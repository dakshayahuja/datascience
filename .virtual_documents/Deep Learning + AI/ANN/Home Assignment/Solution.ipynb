import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout
from scikeras.wrappers import KerasClassifier

from warnings import filterwarnings
filterwarnings("ignore")


df = pd.read_csv("Churn_Modelling.csv", index_col='RowNumber')


df.info()


df.drop(['CustomerId', 'Surname'], axis=1, inplace=True)


df.head()


df = pd.get_dummies(data=df, prefix='Geo', columns=['Geography'])
df[['Geo_France', 'Geo_Germany', 'Geo_Spain']] = df[['Geo_France', 'Geo_Germany', 'Geo_Spain']].astype(int)


df = df.replace(to_replace={'Gender': {'Female': 1,'Male':0}})


df.head()


plt.figure(figsize=(7,4))
sns.countplot(data=df, x=df.Exited, palette=['#cc2936',"#08415c"])
plt.show()


df.hist(figsize=(16,10), color='#2a9d8f')
plt.title("Distribution of features")
plt.show()


plt.figure(figsize=(16,6))
sns.heatmap(df.corr(), annot=True, fmt='0.2f', cmap='flare_r')


fig,ax = plt.subplots(nrows = 4, ncols=3, figsize=(16,12))
row = 0
col = 0
for i in range(len(df.columns) -1):
    if col > 2:
        row += 1
        col = 0
    axes = ax[row,col]
    sns.boxplot(x = df['Exited'], y = df[df.columns[i]],ax = axes, palette=['#f87060','#264653'])
    col += 1
plt.tight_layout()
plt.show()


x = df.drop(['Exited'], axis=1)
y = df['Exited']


x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)


sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)


model = Sequential()
model.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))
model.add(Dense(units = 150, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dense(units = 200, kernel_initializer = 'uniform', activation = 'relu'))
model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))


model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])


model.summary()


EPOCHS = 100
BATCH_SIZE  = 64

l1 = model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, verbose = 0)


# validation loss
plt.style.use("ggplot")
plt.figure(figsize = (12,5))
plt.plot(np.arange(0, EPOCHS), l1.history["loss"], label="train_loss", color='#e63946')
plt.title("ANN: Loss")
plt.xlabel("Epoch #", weight="bold")
plt.ylabel("Loss", weight="bold")
plt.legend()
plt.show()


# validation accuracy
plt.style.use("ggplot")
plt.figure(figsize = (12,5))
plt.plot(np.arange(0, EPOCHS), l1.history["accuracy"], label="train_acc", color='#386641')
plt.title("ANN: Accuracy")
plt.xlabel("Epoch #", weight="bold")
plt.ylabel("Accuracy", weight="bold")
plt.legend()
plt.show()


score, acc = model.evaluate(x_train, y_train)
print('Train score:', score)
print('Train accuracy:', acc)


y_pred = model.predict(x_test)
y_pred = (y_pred > 0.5)
score, acc = model.evaluate(x_test, y_test)
print('Test score:', score)
print('Test accuracy:', acc)


cm = confusion_matrix(y_test, y_pred)


plt.figure(figsize=(7,4))
sns.heatmap(pd.DataFrame(cm), annot=True, fmt='g')
plt.title('Confusion matrix')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')


print(classification_report(y_test,y_pred))


plt.figure(figsize=(8,4))
y_pred_prob = model.predict(x_test)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
plt.plot([0,1],[0,1],'k--')
plt.plot(fpr,tpr, label='ANN')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('ROC curve')
plt.show()


print(roc_auc_score(y_test,y_pred_prob))


def build_classifier():
    classifier = Sequential()
    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))
    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))
    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
    return classifier
classifier = KerasClassifier(build_fn = build_classifier, batch_size = 64, epochs = 50,verbose=0)
accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)
mean = accuracies.mean()
variance = accuracies.std()


print('Mean accuracy score: {}'.format(round(mean*100,2)))
print('Standard Deviation of accuracy score: {}'.format(round(variance,4)))


# Improving the ANN
classifier = Sequential()
classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))
classifier.add(Dropout(rate = 0.1))
classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))
classifier.add(Dropout(rate = 0.1))
classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
classifier.fit(x_train, y_train, batch_size = 64, epochs = 50,verbose = 0)


score, acc = classifier.evaluate(x_train, y_train)
print('Train score:', score)
print('Train accuracy:', acc)

y_pred = classifier.predict(x_test)
y_pred = (y_pred > 0.5)
score, acc = classifier.evaluate(x_test, y_test)
print('Test score:', score)
print('Test accuracy:', acc)

cm = confusion_matrix(y_test, y_pred)


plt.figure(figsize=(7,4))
sns.heatmap(pd.DataFrame(cm), annot=True, fmt='g')
plt.title('Confusion matrix')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.show()


print(classification_report(y_test,y_pred))


plt.figure(figsize=(8,4))
y_pred_prob = model.predict(x_test)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
plt.plot([0,1],[0,1],'k--')
plt.plot(fpr,tpr, label='ANN')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('ROC curve')
plt.show()


print(roc_auc_score(y_test,y_pred_prob))


def build_classifier(optimizer='adam'):
    classifier = Sequential()
    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))
    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))
    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])
    return classifier
    
classifier = KerasClassifier(build_fn = build_classifier,verbose=0)
parameters = {'batch_size': [25, 32],
              'epochs': [100, 200],
              'optimizer': ['adam', 'rmsprop']}

grid_search = GridSearchCV(estimator = classifier,
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 10)

grid_search = grid_search.fit(x_train, y_train,verbose = 0)
best_parameters = grid_search.best_params_
best_accuracy = grid_search.best_score_


print('Best Parameters after tuning: {}'.format(best_parameters))
print('Best Accuracy after tuning: {}'.format(best_accuracy))
